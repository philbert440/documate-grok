# Projects  
This will eventually be a comprehensive list of all of the projects I've worked on over the years going back in time as you scroll down.

## Philbot & This Portfolio Site
This was a fun project that I knocked out in a weekend. First I put together a vitepress site and added some details about past projects, experience, and a short bio with some fun stories. What's nice about vitepress is the documentation is all generated from markdown which make it easy to write and also easy for AI to ingest, I used the OpenAI Embeddings API to generate embeddings from the md files which is all stored in a sqlite db and then thats fed in the Grok-3-mini prompt with gaurd rails defined so that it doesn't make up stuff and sticks to what it knows based on the info I proved here.

## Scaling Shipcode Globally

## Documentation & AI

## Monitoring, Stability, & Security

## Testing, Deployment, & CI/CD

## The Host System

## Real Time Collaboration

## The Canvas System  

## Shipcode from 0-1

## Developer Tooling Overhaul

## Flagship Integrations

## Home Test Pro

## RxSoil Algorithm to AI

## Laboratory SaaS

## Adapify Sports

## We Evolve Us

## Sands Casino Hack

## Microsoft Acquires Nokia

## Adobe on Microsoft

## Netflix in 2013

## Pheon Technologies Group
In 2009, I saw a Microsoft Research video of a touch screen table with infinite points of contact. After seeing that and deciding that I needed one in my apartment. I found NUI(Natural User Interface) group and open source project made up of a couple hundred other like minded individuals around the work attempting to build somethings similar. Community Core Vision was the software to enable multi touch devices using FTIR (Frustrated Total Internal Reflection). This was acheived by placing infrared led strips around the edges of an enlightened acrylic panel, to flood the panel with light. Whenever anything came in contact with the surface that would reflect to the other side where there was a modified PS3 eye cam with an infrared filter to visually pick up the blobs of light being reflected, then Community Core Vision would translate those light blobs into touch input. I also helped with organizing a group buy for a manufacturing run of enlightened acrylic panels for building the devices.

At the time I dismantled my HDTV to pull the LCD matrix out of it, fun fact: LCD doesn't block infrared light so it's kind of the perfect solution to putting image/screen just under the panel that is recognizing the user input from the surface and with a little bit of software and calibration the whole thing works seamlessly. 