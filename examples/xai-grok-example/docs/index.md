# xAI Grok Backend Example

Welcome to the Documate xAI Grok backend example! This demonstrates how to use Documate with xAI's Grok-3-mini model.

## What is Grok-3-mini?

Grok-3-mini is xAI's latest language model, optimized for:

- **Fast Performance**: Quick response times
- **Cost Effectiveness**: More affordable than larger models
- **High Quality**: Excellent response quality
- **Real-time Streaming**: Supports streaming responses
- **Multilingual Support**: Works with multiple languages

## Features

This example showcases:

- **Semantic Search**: Uses xAI's embedding-001 model for finding relevant content
- **Chat Completions**: Uses Grok-3-mini for generating responses
- **Streaming**: Real-time streaming of AI responses
- **Vector Database**: Efficient storage and retrieval of embeddings

## Getting Started

1. Deploy the xAI Grok backend to AirCode
2. Configure your environment variables
3. Upload your documentation content
4. Integrate the frontend component

## Configuration

The backend requires two environment variables:

- `XAI_API_KEY`: Your xAI API key
- `XAI_ORGANIZATION_ID`: Your xAI organization ID

## Usage

Once set up, users can ask questions about your documentation and receive AI-powered responses using Grok-3-mini.

## Benefits

- **Cost Effective**: More affordable than larger models
- **Fast**: Optimized for quick responses
- **Reliable**: High-quality responses
- **Scalable**: Can handle multiple concurrent requests 